\chapter{Results and Analysis} \label{ch:results-analysis}

We demonstrate the output of the Frangi filter on our samples after running a multiscale technique with $N=20$ scales with a stricter anisotropy $\beta = .35$ and $\gamma=0.5$,
with scales spaced logarithmcally from $\sigma_1 = 2^{-1}$ to $\sigma_N = 2^{3.5}$, performing glare and cut removal in preprocessing, and using a discrete gaussian kernel and dilation border of 20.

\section{Sample visual output}
In \cref{fig:output-montage-example1} and \cref{fig:output-montage-example2} we take a partial look at the Frangi output for two particularly well-behaved samples. In the top-left, the preprocessed placenta is shown. In the top-right, the maximum of the Frangi output over $N$ scales. The bottom left and right images are simple segmentation strategies of merging the result.

\begin{figure} \centering
  \includegraphics[width=\textwidth]{montage-T-BN0164923}
  \caption{Sample Multiscale Frangi output ($\beta=0.35$) with simple segmentation strategies (Example 1)}
  \label{fig:output-montage-example1}
\end{figure}

\begin{figure} \centering
  \includegraphics[width=\textwidth]{montage-T-BN0651415}
  \caption{Sample Multiscale Frangi output ($\beta=0.35$) with simple segmentation strategies (Example 2)}
  \label{fig:output-montage-example2}
\end{figure}


\subsection{Binary Classifications and the confusion matrix}

We wish to come up wish a means of gauging the success of our segmentations and will adopt a binary classification model to do so.
We end up with a boolean matrix the size of the image, and compare it to the ground truth, the trace, and then compare them to get the number of true positives, true negatives, false positives, and false negatives. We demonstrate these visually with a confusion matrix, as in cref{fig:sample-confusion}.
\begin{figure}
	\centering
	\includegraphics[width=\textwidth]{sample_confusion}
	\caption{Sample confusion matrix}
	\label{fig:sample-confusion}

\end{figure}
	
Although there are many measures to gauge the succcess of binary classification, we will focus on two. The first is precision, 

\begin{equation}
\label{eq:precision}
\textrm{precision} \;=\; \frac{TP}{TP+FP}
\end{equation}

and the second is the Matthews Correlation Constant (MCC), given by

\begin{equation} \label{eq:MCC}
MCC = \frac{TP\times TN - FP \times FN}{\sqrt{ (TP + FP)(TP+FN)(TN+FP)(TN+FN)}}
\end{equation}

where precision is a ratio between 0 \% and 100\% and the MCC is a measure between -1 and 1. Precision (or positive predictive power) is of course a ratio between how many labels we got correct over all pixels we labeled as positive. This is a useful score for us--if we are using Frangi as a prefiltering for a more robust technique, we would not want to provide any wrong information or seeds to that algorithm. Precision therefore does an okay job of representing that scenario: we are not penalized for what we do not label as true, as long as our reports of true are correct.

Of course, we cannot rely on precision as our sole quantiative factor alone--we could simply return everything negative and recieve a perfect score of 100\% precision. Therefore we will gauge that measure with that of the MCC \cite{mcc-original-paper}. The main advantage of the MCC is that is well balanced no matter what the size of the two classes are, and will only be high if the approximation scores well against both labels. A score of $1.0$ means the approximation is 100\% correct, a score of $-1$ means that everything is completely incorrect, and a score of $0$ means that the test peforms as well as random guessing.  We will consider these two measures at the same time--saying that we would like an MCC score as high as possible, but will contextually settle for a lower score as long as the approximation is still textit{precise}.

One final point about these measures is that we have decided to report their scores only within the placental plate, rather than the entire rectangular image. Since the area outside of plate is masked from consideration, those points will be true negatives no matter what, and we don't want this artificial padding to influence our score. That being said, we do currently concede one part right now: we will also mask an area around the umbilical cord insertion point, as the large amount of noise here will mean that our scores are artificially low. We would like to remove these areas, but for now we will simply not score them. 




In \cref{fig:segmentation-demo} we demonstrate the visual outputs produced by \texttt{extract\_NCS\_pcsvn.py}. This particular sample, BN4569506, is a relatively well-behaved sample, and segmentation was comparatively successful. On the left column we have 

%\begin{figure}
%\centering
%\includegraphics[height=\textheight]{BN4569506_output-montage}
%\caption{Demonstration of postprocessing techniques}
%\label{fig:segmentation-demo}
%\end{figure}

\begin{figure}
	\begin{minipage}[tp]{0.5\textwidth}
		\includegraphics[height=0.95\textheight]{M1-T-BN2050224}
	\end{minipage}
	\quad
	\begin{minipage}[tp]{0.35\textwidth}
		\begin{tabular}{l|r|r|r}
			n  & $\sigma_n$  &  $\alpha_p$  &  $\max(V_\sigma)$ \\
			\hline
			0  &   0.3535 &  0.0547 &  0.986\\
			1  &   0.4243 &  0.0590 &  0.979\\
			2  &   0.5092 &  0.0654 &  0.970\\
			3  &   0.6110 &  0.0765 &  0.973\\
			4  &   0.7333 &  0.0892 &  0.988\\
			5  &   0.8801 &  0.0962 &  0.991\\
			6  &   1.0562 &  0.1082 &  0.991\\
			7  &   1.2676 &  0.1308 &  0.970\\
			8  &   1.5212 &  0.1669 &  0.973\\
			9  &   1.8256 &  0.2232 &  0.978\\
			10 &   2.1909 &  0.2925 &  0.984\\
			11 &   2.6294 &  0.3196 &  0.968\\
			12 &   3.1555 &  0.3269 &  0.994\\
			13 &   3.7869 &  0.3558 &  0.998\\
			14 &   4.5447 &  0.4058 &  0.999\\
			15 &   5.4542 &  0.3764 &  0.963\\
			16 &   6.5456 &  0.3184 &  0.950\\
			17 &   7.8553 &  0.3047 &  0.958\\
			18 &   9.4272 &  0.3287 &  0.916\\
			19 &  11.3137 &  0.3524 &  0.916\\
		\end{tabular} \\
	\end{minipage}
	\caption{Vesselness scores and percentile thresholds}
\end{figure}

\begin{figure}[p] \centering
	\includegraphics[width=\linewidth]{M2-T-BN2050224}
	\caption{Sample of Frangi-based Segmentation Methods (pt. 2)}
\end{figure}

\begin{table}[p]\centering
	\begin{tabular}{l|rrrr}
		{} &        PF &        FA &        RW &        PS \\
		\hline
		MCC           &  0.4872 &  0.4208 &  0.5249 &  0.4877 \\
		%\hline
		skel coverage &  0.5085 &  0.3245 &  0.4493 &  0.4650 \\
		%\hline
		precision     &  0.8044 &  0.9472 &  0.8858 &  0.8697 \\
	\end{tabular}
	\caption{Scores for merging techniques}
\end{table}

\section{Variations in the Data Set and Imperfections of the Ground Truth} \label{sec:NCS-dataset-issues}
\
\begin{sidewaysfigure}
	\includegraphics[width=\textwidth]{annotations-montage-2by2}
	\caption{Issues in ground truth manifesting in Frangi vesselness scores}
	\label{fig-annotated-montage}
\end{sidewaysfigure}




Sometimes the output doesn't agree with the trace, i.e. ``the ground truth'' is not 100\% correct.
sometimes either there's a false negative (reported) but something just wasn't traced in the original  1602443.

\begin{figure} \centering
  \subfloat{
  \includegraphics[width=0.5\textwidth]{T-BN0392644_inset}
}
\subfloat{
  \includegraphics[width=0.5\textwidth]{T-BN0392644_inset_ctrace}
} \\
\subfloat{
  \includegraphics[width=0.5\textwidth]{T-BN0392644_inset_sketches}
}
\subfloat{
  \includegraphics[width=0.5\textwidth]{T-BN0392644_inset_mark}
}
\caption{Issues with ground truth and sample quality}
\label{fig:groundtruth-samplequality}
\end{figure}

As seen in \cref{fig:groundtruth-samplequality}, there are several issues with the samples that will cause trouble in our efforts toward segmentation. Our represenative sample is BN0392644. The top left is the original (color) image, the top right is the full vessel width trace. The bottom left is a smaller skeletonization (sketch), where arteries are shown in red and veins are shown in blue. The bottom right figure contains some annotations. At the top, a blue arrow indicates a large curvilinear patch of dried blood that is not part of the vascular network. The green arrow in the middle indicates some vessels that are too small for the diameter binning and are thus not reported. We will see later that our Frangi result perfectly captures these, yet they will be reported as a false positive since they are not part of the tracing. However, there are other vessels of similar visual width in this same inset that are traced. In blue boxes (and in many other spots) the vessels cross each other. The border around these will prevent us from being able to extract the vessel directly. In the green dotted box, a major arterial and a major venous branch each connect to the umbilical cord insertion point. Whereas the arterial branch (on the right) can be seen, it will not be reported by the Frangi filter, since those points are not darker relative to the background. You can also see how much variation there is as you look along a blood vessel. There are some areas where the Frangi filter will have a very limited response. 



\begin{enumerate}
\item Collar is stupid and should really be considered like a error in marking the perimeter. Throw these away or edit. Maybe make a section called discarded samples that's stupid but yeah.
\item Vessels suck sometimes. In the portion above, 1602443, there's a random blood clot which gets identified at large $\sigma$. But also the small forked shaped thing which is obviously a vessel doesn't get defined.
\item Too much blood (not enough?? no idea) is left in the vessels. leading to the weird white border around some vessels. you could identify these along with black center and combine them somehow. no idea.Also, holy shit, some of the white vessel ``sleeves'' ARE identified in the tracing, and some aren't. Find an example of this and whine about it.
\item Umbillical cord insertion point is stupid and obscures a lot. The tracer guesses but there's no real guiding principle AFAIK..
\item Small vessels aren't accounted for at all. Not sure how to coincide measurement in terms of scale space anymore, but should figure out how to cut off those values before running MCC metric.
\end{enumerate}





\section{Results}

%\begin{itemize}
%	\item Relationship between traced pixelwidths vs the scale they were pulled from.
%	\item Frangi behavior at max scale length and if there's anything that gets too large (related to first derivatives maybe?
%	\item calculate the actual weingarten map eigenvectors (although this is
%	probably gonna be very fake in a discrete sense).
%	\item difference between using green channel and non-green channel.
%\end{itemize}



\begin{figure}[p]
  \includegraphics[width=\textwidth]{test-scale-width}
  \caption{Pixel Width of Ground Truth vs. Scale Length for True Positives}
\end{figure}

\begin{figure}[p]\centering
  \subfloat{
  \includegraphics[width=0.85\textwidth]{Vmax_to_scale_normalized}
  }\\[-0.5cm]
  \subfloat{
  \includegraphics[width=0.85\textwidth]{frangi_argmax-trace}
  }
  \caption{Scale of maximum Frangi score for true positives and false negatives}
\end{figure}

\begin{figure}[p]\centering
  \subfloat{
    \includegraphics[width=0.85\textwidth]{Vmax_to_scale_normalized_with_approx}
  }\\[-0.5cm]
  \subfloat{
    \includegraphics[width=0.85\textwidth]{frangi_argmax-trace-approx}
  }
  \caption{Scale of maximum Frangi score for true positives only (percentile filtering)}
\end{figure}
